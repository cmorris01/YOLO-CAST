{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv8 demo for CAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run block for required dependencies:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to download requirements into virtual environment\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import statements:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Importing training dataset for demo</u>\n",
    "\n",
    "For this demo, we will be training a YOLOv8 on African wildlife imagery pulled from https://ultralytics.com/assets/african-wildlife.zip. From ultralytics, \"This dataset showcases four common animal classes typically found in South African nature reserves. It includes images of African wildlife such as buffalo, elephant, rhino, and zebra, providing valuable insights into their characteristics. Essential for training computer vision algorithms, this dataset aids in identifying animals in various habitats, from zoos to forests, and supports wildlife research.... \n",
    "\n",
    "The African wildlife objects detection dataset is split into three subsets:\n",
    "\n",
    "Training set: Contains 1052 images, each with corresponding annotations.\n",
    "Validation set: Includes 225 images, each with paired annotations.\n",
    "Testing set: Comprises 227 images, each with paired annotations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using requests, download zip file and extract contents\n",
    "\n",
    "# url of zipfile\n",
    "url_of_zip = 'https://ultralytics.com/assets/african-wildlife.zip'\n",
    "url_of_yaml = 'https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/datasets/african-wildlife.yaml'\n",
    "\n",
    "# directory to be saved into\n",
    "wd = os.getcwd()\n",
    "zip_directory = os.path.join(wd, 'animals.zip')\n",
    "yaml_directory = os.path.join(wd, 'data.yaml')\n",
    "\n",
    "# download request\n",
    "response = requests.get(url_of_zip)\n",
    "with open(zip_directory, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "response2 = requests.get(url_of_yaml)\n",
    "with open(yaml_directory, 'wb') as f:\n",
    "    f.write(response2.content)\n",
    "\n",
    "# use the working directory as the extraction target\n",
    "extract_to = wd  # Since we're extracting to the working directory\n",
    "\n",
    "# extract the zip file\n",
    "with zipfile.ZipFile(zip_directory, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Clear directory of training files if needed:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize file name\n",
    "file_name = 'animals.zip'\n",
    "file_name2 = 'data.yaml'\n",
    "\n",
    "# construct the file path\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "file_path2 = os.path.join(os.getcwd(), file_name2)\n",
    "\n",
    "# delete the zip file\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"The file {file_name} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exist.\")\n",
    "\n",
    "# delete the zip file\n",
    "if os.path.exists(file_path2):\n",
    "    os.remove(file_path2)\n",
    "    print(f\"The file {file_name2} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The file {file_name2} does not exist.\")\n",
    "\n",
    "# list of directory paths you want to delete\n",
    "directories = [\"./train\", \"./test\", \"./valid\"]\n",
    "\n",
    "# loop through each directory in the list\n",
    "for directory_path in directories:\n",
    "\n",
    "    # check if the directory exists\n",
    "    if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "        \n",
    "        # use shutil.rmtree() to delete the directory\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"The directory {directory_path} has been deleted.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"The directory {directory_path} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Training the detection model on local machine</u>\n",
    "\n",
    "This block will train the YOLO model using your local machine. Depending on the size of the training/val data and model size, this could be too computationally intensive for your hardware; we will discuss using UARK's high performance computing center if this is the case.\n",
    "\n",
    "<b>Hyperparameters</b>\n",
    "\n",
    "YOLOv8 has a handful of customizable hyperparameters you can read about here: https://docs.ultralytics.com/usage/cfg/#train-settings. Hyperparameters affect how YOLO is trained and can subsequently affect accuracy and time of convergence.\n",
    "\n",
    "This code block will prompt you for a few commonly customized hyperparameters.\n",
    "\n",
    "A note about batch size and optimizer: using batch size = -1 will find the computationally optimal batch size for your local machine. Similarly, using optimizer = auto will do the same.\n",
    "\n",
    "<b>Configuration</b>\n",
    "\n",
    "In your working directory, there should now be train, test, and valid folders. These are the image sets and associated annotations YOLO will be trained on. There should also be a data.yaml file; this yaml file tells the model the configuration of your directory, i.e. where to find the training data it needs.\n",
    "\n",
    "<b>Tensorboard Updates</b>\n",
    "\n",
    "TensorBoard offers an enhanced visualization experience for monitoring the YOLO (You Only Look Once) training process, providing deep insights into various metrics such as loss components, learning rate, and performance indicators like precision, recall, and mean Average Precision (mAP). Its integration with YOLO allows for real-time tracking of these metrics, enabling the identification and resolution of training challenges swiftly. The visualization of weight distributions, feature maps, and prediction outcomes further aids in understanding the model's learning behavior. \n",
    "\n",
    "TensorBoard will also provide a training time for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda GPU training is available. if not, set to CPU training.\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device(\"cuda\")\n",
    "else:\n",
    "    device_name = torch.device('cpu')\n",
    "print(\"Using {}.\".format(device_name))\n",
    "\n",
    "# load a model\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.to(device_name)\n",
    "\n",
    "# prompt for hyperparameters\n",
    "print(\"\\033[1m\" + \"Hyperparameter intialization\" + \"\\033[0m\")\n",
    "\n",
    "# epochs\n",
    "print(f'Enter the number of epochs: ')\n",
    "epochs = int(input())\n",
    "print(epochs)\n",
    "\n",
    "# batch size\n",
    "print(f'Enter the batch size: ')\n",
    "batch_size = int(input())\n",
    "print(batch_size)\n",
    "\n",
    "# optimizer\n",
    "print(f'Enter the optimizer (SGD, Adam, AdamW, NAdam, RAdam, RMSProp, or auto): ')\n",
    "optimizer = input()\n",
    "print(optimizer)\n",
    "\n",
    "# cos_lr\n",
    "print('Enter status of cos_lr (False or True): ')\n",
    "cos_lr = bool(input())\n",
    "print(cos_lr)\n",
    "\n",
    "# train model\n",
    "results = model.train(data=\"data.yaml\", epochs=epochs, batch=batch_size, optimizer=optimizer, cos_lr=cos_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Training the detection model on UARK's high performance computing servers</u>\n",
    "\n",
    "Once again, training machine learning models on a laptop or PC is possible on a couple thousand of images, but the model tuning is demanding of most PC and laptop processers. Industrial scale GPUs, like NVIDIA's V100, are designed to execute a greater load of operations at the same time and are well equipped for math heavy machine learning algorithms. These GPUs allow for fitting models with a more complicated architecture to a larger dataset. \n",
    "\n",
    "The Arkansas HPC (High performance computer) server has 20 Industrial scale GPUs for computationally heavy programs. The AHPCC is available to faculty, staff and students at all of the Arkansas public universities. \n",
    "\n",
    "For our purposes, we will train the same model on a larger set of training data using these GPUs. Our process will walk through how to run these files on the AHPC server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the University of Arkansas HPC Server\n",
    "\n",
    "<u> Setup </u>\n",
    "\n",
    "You will need an account to use the GPUs on the AHPC server.\n",
    "U of A students can request an account to use the AHPC here: https://hpc.uark.edu/hpc-support/user-account-requests/internal.php\n",
    "\n",
    "You must be connected to university wifi or connected to the university VPN. Connections outside of the university network will fail on the server side.\n",
    "\n",
    "Test your connection by signing in to a login node. Enter a bash terminal and log in with this command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <username> should be replaced by your uark username\n",
    "ssh <username>@hpc-portal2.hpc.uark.edu \n",
    "# This will prompt you to enter your UARK password to finish connecting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now able to upload files to the server that may run on the AHPC GPU nodes. Now we need to format files to send to the server GPU. A computation node needs to know the code to run, the files that a code script accesses, and the packages necessary to run the script. \n",
    "\n",
    "1) Convert notebook code to python script\n",
    "2) Locate all build files and training data to one location\n",
    "3) Send the python environment needed to train the data as a container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Python Script\n",
    "\n",
    "Copy and paste the next to code chunk into a new python script. Call it \"train_model.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_model.py\n",
    "~~~~~~~~~~~~\n",
    "Used to train YOLO models on UARK hpc.\n",
    "\"\"\"\n",
    "\n",
    "# Setting environmental variable and import statements\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from typing import List, Any\n",
    "import pandas as pd\n",
    "\n",
    "# Specifying cuda GPU memory allocation. Required in google colab to deal with memory overrun, using as safeguard for HPC\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'\n",
    "\n",
    "# Intializing GPU use if available for training.\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device(\"cuda\")\n",
    "else:\n",
    "    device_name = torch.device('cpu')\n",
    "print(f\"Using {device_name} for training.\")\n",
    "\n",
    "# load a model\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.to(device_name)\n",
    "\n",
    "# prompt for hyperparameters\n",
    "print(\"\\033[1m\" + \"Hyperparameter intialization\" + \"\\033[0m\")\n",
    "\n",
    "# epochs\n",
    "print(f'Enter the number of epochs: ')\n",
    "epochs = int(input())\n",
    "print(epochs)\n",
    "\n",
    "# batch size\n",
    "print(f'Enter the batch size: ')\n",
    "batch_size = int(input())\n",
    "print(batch_size)\n",
    "\n",
    "# optimizer\n",
    "print(f'Enter the optimizer (SGD, Adam, AdamW, NAdam, RAdam, RMSProp, or auto): ')\n",
    "optimizer = input()\n",
    "print(optimizer)\n",
    "\n",
    "# cos_lr\n",
    "print('Enter status of cos_lr (False or True): ')\n",
    "cos_lr = bool(input())\n",
    "print(cos_lr)\n",
    "\n",
    "# train model\n",
    "results = model.train(data=\"data.yaml\", epochs=epochs, batch=batch_size, optimizer=optimizer, cos_lr=cos_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locate all build files and training data to one folder\n",
    "\n",
    "Make a copy of this directory and remove the python notebook from the new directory. The script, yaml file, and training data should be the only files in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r upload_folder <current_dir> ..   #bash command to copy the '<current_dir>' called 'upload_folder' to the parent folder\n",
    "cd ..\n",
    "cd upload_folder                        # Enter the upload folder\n",
    "rm *.ipynb\n",
    "ls -a                                   # print all files in the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a folder called \"images\" that contains two folders of images and labels: one for training and one for validation. Both training and validation folders should have two folders inside: one for all of the images and one for all labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Output of training </u>\n",
    "\n",
    "By the end of training, YOLO models provide several key outputs that give insights into the model's performance and its capability to detect objects in images.\n",
    "\n",
    "<b> Loss Function </b>\n",
    "\n",
    "The loss function is a critical output of the training process, as it quantifies how well the YOLO model is performing. YOLO's loss function is composed of several components:\n",
    "\n",
    "- **Localization Loss**: Measures how accurately the model predicts the location of bounding boxes for each detected object.\n",
    "- **Confidence Loss**: Represents the error in the confidence scores for the bounding boxes, including those boxes that do not contain objects (background).\n",
    "- **Classification Loss**: Calculates the error in predicting the class of the detected objects.\n",
    "\n",
    "Monitoring the loss function during training helps in understanding how well the model learns to detect objects and classify them. A decreasing loss over epochs indicates that the model is learning effectively.\n",
    "\n",
    "<b> Precision and Recall </b>\n",
    "\n",
    "After training, evaluating the model's performance involves looking at precision and recall metrics:\n",
    "\n",
    "- **Precision**: Indicates the accuracy of the predictions, i.e., the percentage of correct positive predictions out of all positive predictions made.\n",
    "- **Recall**: Measures the model's ability to detect all relevant instances, i.e., the percentage of correct positive predictions out of all actual positives.\n",
    "\n",
    "These metrics are crucial for understanding the trade-off between correctly detecting objects (recall) and minimizing false positives (precision).\n",
    "\n",
    "<b> mAP (Mean Average Precision) </b>\n",
    "\n",
    "mAP is a comprehensive metric used to evaluate the accuracy of object detectors like YOLO. It averages the precision-recall curve into a single value, providing an overall measure of the model's performance across all classes and IoU (Intersection over Union) thresholds. High mAP values indicate a robust model capable of accurately detecting and classifying objects across different scenarios.\n",
    "\n",
    "<b> Detection Speed </b>\n",
    "\n",
    "YOLO is designed for real-time object detection, and its detection speed (usually measured in FPS, frames per second) is a crucial output. This metric tells us how fast the model can process images to detect objects, which is vital for applications requiring real-time analysis, such as video surveillance and autonomous driving.\n",
    "\n",
    "<b> Visualization of Detections </b>\n",
    "\n",
    "Finally, visualizing the detections made by the YOLO model on test images or videos is an intuitive way to understand the model's performance. These visualizations typically include bounding boxes around detected objects, class labels, and confidence scores. They provide immediate visual feedback on how well the model can detect and classify objects in various conditions.\n",
    "\n",
    "<b> Trained Model Directory Structure </b>\n",
    "\n",
    "After successfully training a YOLO model, the next steps involve accessing the trained model for inference or further fine-tuning. The trained model weights are typically saved in a specific directory structure, often under a `weights` folder and within `runs` folders for different experiments. Understanding how to navigate these folders and use the saved weights is crucial for applying your YOLO model to real-world tasks.\n",
    "\n",
    "- **Weights Folder**: This folder contains the saved weights of your model after training. YOLO saves weights at regular intervals during training, as well as the final weights once training is complete. The saved weights include:\n",
    "  - `best.pt`: The weights of the model that achieved the best performance on the validation set during training.\n",
    "  - `last.pt`: The weights of the model at the last training epoch. These may not be the best-performing weights but are useful for resuming training.\n",
    "  \n",
    "- **Runs Folder**: The `runs` folder is organized by training experiments. Each experiment (or training run) has its own subfolder, typically named with the experiment's start date and time or a custom name you specify. Within each experiment's folder, you'll find:\n",
    "  - Subfolders for each training phase (e.g., `train`, `val`), containing logs and outputs specific to those phases.\n",
    "  - TensorBoard logs, if TensorBoard was used during training, allowing you to visually monitor the training process.\n",
    "  - Any additional outputs specified during training, such as plots of the loss function over time, precision-recall curves, and example predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Clear runs and trained model if needed:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize file name\n",
    "file_name = 'yolov8n.pt'\n",
    "\n",
    "# construct the file path\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "# delete the zip file\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"The file {file_name} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exist.\")\n",
    "\n",
    "# list of directory paths you want to delete\n",
    "directory_path = \"./runs\"\n",
    "\n",
    "# check if the directory exists\n",
    "if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "    \n",
    "    # use shutil.rmtree() to delete the directory\n",
    "    shutil.rmtree(directory_path)\n",
    "    print(f\"The directory {directory_path} has been deleted.\")\n",
    "\n",
    "else:\n",
    "    print(f\"The directory {directory_path} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Using the model for inference</u>\n",
    "\n",
    "Once a model is trained, it can be used for infernecnce on "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
